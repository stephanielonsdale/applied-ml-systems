{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Product Recommendation System (Embedding-Based)\n",
        "\n",
        "This notebook implements a semantic product recommender using transformer-based embeddings.\n",
        "Given a product query, the system retrieves similar products based on cosine similarity in embedding space.\n",
        "\n",
        "**Techniques used:**\n",
        "- Text preprocessing & feature construction\n",
        "- Transformer embeddings (Sentence-BERT)\n",
        "- Cosine similarity for retrieval\n",
        "- Recommendation ranking & evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ6LSlGMgFth"
      },
      "outputs": [],
      "source": [
        "# Correct the file path to the actual location of the dataset\n",
        "data = pd.read_csv('/Users/stephanielonsdale/Shopeasy_product_dataset.csv', low_memory=True)\n",
        "# low_memory=True in pd.read_csv() allows Pandas to read large CSV files in chunks, reducing memory usage and preventing dtype-related warnings.\n",
        "\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSCpbWQVjooV"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU_1TITaXtMy"
      },
      "source": [
        "1. `data.drop_duplicates(inplace=True)`\n",
        "- This removes duplicate rows from the DataFrame `data`.\n",
        "- The parameter `inplace=True` ensures that the operation is performed directly on `data` without needing to assign it back.\n",
        "2. `data.shape`\n",
        "- This returns the shape of the DataFrame as a tuple `(rows, columns)`, allowing you to check the number of rows and columns after duplicates have been removed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV6gSk0KhXoL"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(inplace=True)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvsYk9GBGS9y"
      },
      "source": [
        "Compute the count of missing values in each column to identify data cleaning requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xVqzYGijdCA"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BdMT_Y9GXyx"
      },
      "source": [
        "Replace all missing values with an empty string to avoid issues during text processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm-1cwyxqGq3"
      },
      "outputs": [],
      "source": [
        "data.replace(np.nan, '', inplace=True)\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vePcITY9yF-h"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qC_AWR27yZm7"
      },
      "outputs": [],
      "source": [
        "data = data.astype(str)\n",
        "data = data.applymap(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5Is8szpPXVi"
      },
      "source": [
        "* The dataset likely contains text data with special characters, punctuation, and unnecessary symbols.\n",
        "* This step removes all non-alphanumeric characters using `re.sub('[^A-Za-z0-9]+', ' ', str(x))`.\n",
        "* The function is applied to every cell in the dataframe using `applymap()`, ensuring that all text-based entries are cleaned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tla9nnlryslM"
      },
      "outputs": [],
      "source": [
        "# Data cleaning, removing any non alphanumeric characters\n",
        "import re\n",
        "data = data.applymap(lambda x: re.sub('[^A-Za-z0-9]+', ' ', str(x)))\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI2qZpU4a5bF"
      },
      "source": [
        "This creates a new column `combined_text` by concatenating multiple textual columns:\n",
        "- product_name\n",
        "- product_category_tree\n",
        "- description\n",
        "- brand\n",
        "- product_specifications\n",
        "\n",
        "Each value is joined with a space (`' '`) to maintain readability.\n",
        "This is useful for NLP tasks like product recommendation, search ranking, or semantic analysis.\n",
        "python\n",
        "Copy\n",
        "Edit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTZCEPJFlE5J"
      },
      "outputs": [],
      "source": [
        "data['combined_text'] = data['product_name'] + ' ' +  data['product_category_tree'] + ' ' +  data['description'] + ' ' +  data['brand'] + ' ' +  data['product_specifications']\n",
        "data['combined_text'].astype(str)\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBdzgIhyzF0n"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0sACQ8OQjrcV"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')         # Loads the pre-trained BERT-base model\n",
        "\n",
        "\n",
        "# This model can be used for various NLP tasks, such as text classification, named entity recognition (NER), and sentence embeddings.\n",
        "# Ensure the model is moved to the GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "upLnJ1cij7fd"
      },
      "outputs": [],
      "source": [
        "def bert_tokenization(text):\n",
        "    # Tokenize the sentences\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    # Add [CLS] and [SEP] tokens\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "    # Initialize an empty list to store chunk embeddings\n",
        "    chunk_embeddings = []\n",
        "\n",
        "    # Split the tokenized text into chunks of 512 tokens each (accounting for [CLS] and [SEP] tokens)\n",
        "    max_length = 512 - 2  # 512 total tokens minus [CLS] and [SEP]\n",
        "\n",
        "    # Split into chunks of 510 tokens + [CLS] and [SEP] tokens\n",
        "    for i in range(0, len(tokens), max_length):\n",
        "        chunk = tokens[i:i + max_length]\n",
        "\n",
        "        # Add [CLS] and [SEP] tokens to each chunk\n",
        "        chunk = ['[CLS]'] + chunk + ['[SEP]']\n",
        "\n",
        "        # Convert tokens to input IDs\n",
        "        input_ids = torch.tensor(tokenizer.convert_tokens_to_ids(chunk)).unsqueeze(0).to(device)  # Move input_ids to GPU\n",
        "\n",
        "        # Get the embeddings for the chunk\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids)  # This will be on the same device as input_ids (GPU)\n",
        "            chunk_embedding = outputs.last_hidden_state[:, 0, :]  # [CLS] token embedding\n",
        "            chunk_embeddings.append(chunk_embedding.squeeze().cpu().numpy())  # Move the embedding back to CPU and convert to numpy\n",
        "\n",
        "    # Combine the embeddings of the chunks (e.g., averaging them)\n",
        "    combined_embedding = np.mean(chunk_embeddings, axis=0)\n",
        "\n",
        "    return combined_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFa5V_ic9fA9"
      },
      "source": [
        "- Use `tqdm.pandas()`: This enables progress tracking for .apply() operations.\n",
        "- Apply `bert_tokenization`: The `bert_tokenization` function (analyzed earlier) generates BERT embeddings for the `combined_text` column.\n",
        "- Store embeddings in a new column `\"Embeddings\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQWIZ3-1j-iI"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# BERT Embeddings for the product\n",
        "data[\"Embeddings\"] = data['combined_text'].progress_apply(bert_tokenization)\n",
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxvExP6Om6da"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YgmER534c7k"
      },
      "outputs": [],
      "source": [
        "text = \"T-shirt\"\n",
        "embeds = bert_tokenization(text)\n",
        "embeds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1xcXEPPqxin"
      },
      "source": [
        "- Retrieve the first embedding from `data['Embeddings']`.\n",
        "- `data['Embeddings'][0]` accesses the **first stored embedding**.\n",
        "- We print temp to check its contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ciCEcfJ978a"
      },
      "outputs": [],
      "source": [
        "temp =  data['Embeddings'][0]  # Get the actual array/tensor\n",
        "print(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqYt682k_IL2"
      },
      "outputs": [],
      "source": [
        "print(data['Embeddings'].keys())        # Print all available keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAs53UcZLslI"
      },
      "source": [
        "- We check if the key 19614 exists in `data['Embeddings']`.\n",
        "- This prevents errors when trying to access missing embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdb7dazB_bGw"
      },
      "outputs": [],
      "source": [
        "print(19614 in data['Embeddings'])  # Should return True or False\n",
        "print(data['Embeddings'].keys())  # Check available keys\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53frDwUow_Br"
      },
      "source": [
        "Compute the **cosine similarity** between `\"T-shirt\"`'s embedding and a product at index `19614`.\n",
        "\n",
        "ðŸ”¹ **Cosine similarity measures** how similar two vectors are, with:\n",
        "\n",
        "- <font color='blue'>**1.0 </font>â†’ Exactly the same**\n",
        "- <font color='blue'>**0.0 </font>â†’ Completely different**\n",
        "- <font color='blue'>**Negative values </font>â†’ Opposite meaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5Z1hPnj6Qu9"
      },
      "outputs": [],
      "source": [
        "## ?? Your solution here\n",
        "#compute cosine similarity between \"T-shirt\"'s embedding and a product at index 19614\n",
        "cosine_similarity([embeds], [data['Embeddings'][19614]]).tolist()[0][0] \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cosine similarity of 0.733, close to 1.0, indicating that they are pretty similar!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pgr-wfVxQOL"
      },
      "source": [
        "- Generate embeddings for `\"Fastrack Watches for men\"`.\n",
        "- Iterate through `data['Embeddings']` and calculates cosine similarity with the query.\n",
        "- Store similarity scores in a new column `\"SS\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NvR9IVo2QEF"
      },
      "outputs": [],
      "source": [
        "text = \"Fastrack Watches for men\"\n",
        "embeds = bert_tokenization(text)\n",
        "data['similarity_score'] = 0\n",
        "for idx, val in enumerate(data['Embeddings']):\n",
        "  data['similarity_score'][idx] = cosine_similarity([embeds], [val])\n",
        "\n",
        "# Sorts the dataset based on similarity (SS) in descending order.\n",
        "# Displays the top 10 recommended products.\n",
        "\n",
        "recommendations = data.sort_values(by='similarity_score', ascending=False)\n",
        "recommendations.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2Ep2Wi33oiE"
      },
      "outputs": [],
      "source": [
        "for i in recommendations.product_name.head(10):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmhp6jxbMt-u"
      },
      "source": [
        "The recommendations generated for the query \"Fastrack watch for men\" appear to be inaccurate, as they include unrelated items like shirts, jeans, and shoes instead of watches.\n",
        "\n",
        "This suggests that the **embedding-based retrieval** needs improvement, possibly by using Transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DZZCtblxoqn"
      },
      "source": [
        "* Loads a **pre-trained sentence transformer model**: `'all-mpnet-base-v2'`.\n",
        "* This model **generates sentence embeddings** more efficiently than traditional BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "L-QQHmmR0rfn"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "bert = SentenceTransformer('all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ZATJZ3xzcv"
      },
      "source": [
        "#### **Convert `combined_text` into dense vector embeddings using Sentence Transformers.**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8pW0dx-NDMm"
      },
      "source": [
        "We convert **combined_text** into dense vector embeddings using **Sentence Transformers** to represent textual data in a numerical format that captures semantic meaning. The process:\n",
        "\n",
        "**1. Text to Vector Transformation:**\n",
        "\n",
        "- **Sentence Transformers** (like BERT) generate high-dimensional numerical representations of text, where semantically similar texts have closer vector representations.\n",
        "\n",
        "**2. Contextual Meaning Capture:**\n",
        "\n",
        "- Unlike traditional methods (like TF-IDF or Word2Vec), these embeddings consider context, making them effective for tasks like **recommendation systems**, **clustering**, and **similarity search**.\n",
        "\n",
        "**3. Efficient Similarity Matching:**\n",
        "\n",
        "- These embeddings allow us to use **cosine similarity or nearest neighbor search** to find similar items efficiently, improving recommendation accuracy.\n",
        "\n",
        "By encoding `combined_text` into embeddings, we prepare the data for **fast and meaningful similarity comparisons**, crucial for retrieval-based applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEENgSMw0wqP"
      },
      "outputs": [],
      "source": [
        "# Compute embeddings for the combined_text using Sentence Transformers\n",
        "embeddings = bert.encode(\n",
        "    data[\"combined_text\"].astype(str).tolist(),\n",
        "    batch_size=64,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings=True\n",
        ")\n",
        "\n",
        "# Store one vector per row in a single column\n",
        "data[\"Embeddings_ST\"] = [emb for emb in embeddings]  # list of 1D arrays\n",
        "\n",
        "# quick check\n",
        "print(type(data.loc[0, \"Embeddings_ST\"]), len(data.loc[0, \"Embeddings_ST\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttd9BNOpynkk"
      },
      "source": [
        "Save embeddings as a `.npy` file to avoid recomputation (since embedding generation is GPU-intensive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CDAXXnmA3M4e"
      },
      "outputs": [],
      "source": [
        "# Saving the embedding for further useage as it is a time consuming and GPU intensive task to create the embeddings.\n",
        "embeddings_path = \"/Users/stephanielonsdale/embeddings.npy\"\n",
        "np.save(embeddings_path, embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX5EEzTszakV"
      },
      "source": [
        "- Encodes the **query text**.\n",
        "- Computes **cosine similarity** between the query embedding and all stored product embeddings.\n",
        "- Sorts products by **similarity score** and returns the **top 10 recommendations**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI4bx3Av8B43"
      },
      "source": [
        "Apply sentence transformer embeddings to `combined_text` and stores them in `data['embeds']`.\n",
        " - *Additionally we are also showing the progress bar here for better visualization*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Ou_qxPus9xpL"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(query, top_k=10):\n",
        "    query_embedding = bert.encode([query])\n",
        "    similarity_scores = cosine_similarity(query_embedding, data['embeds'].tolist())\n",
        "    top_indices = np.argsort(similarity_scores[0])[::-1][:top_k]\n",
        "    recommendations = data.iloc[top_indices]['product_name']\n",
        "    return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdIssSE94on2"
      },
      "outputs": [],
      "source": [
        "data['embeds'] = data.combined_text.progress_apply(bert.encode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaxEIgPi7llY"
      },
      "source": [
        "Find products similar to `\"Fastrack Watches for men\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xe9bnxfd5F4b"
      },
      "outputs": [],
      "source": [
        "get_recommendations(\"Fastrack Watches for men\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZDtBRhX7zn5"
      },
      "source": [
        "Find products similar to `\"asics running shoes\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTrAuJz14mv2"
      },
      "outputs": [],
      "source": [
        "get_recommendations(\"asics running shoes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oul2MkbaT7BR"
      },
      "source": [
        "**When Brand Does Not Exist in product_name**\n",
        "\n",
        "- When the brand (e.g., Sony) is not found in `product_name`, the function still retrieves semantically similar products based on **features** like \"wireless,\" \"earbuds,\" and \"battery life.\"\n",
        "\n",
        "- It converts the query into an embedding using BERT, then computes **cosine similarity** with all product embeddings. The **top 10 most similar products** are selected, even if they belong to different brands. This happens because the function prioritizes semantic meaning over exact keyword matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-5QlLCktuhm"
      },
      "outputs": [],
      "source": [
        "get_recommendations(\"Sony noise-canceling wireless earbuds with long battery life\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1Cw2JDogIw"
      },
      "source": [
        "To achieve final evaluation and visualizations, we need to:\n",
        "\n",
        "1. **Run the recommendation function** (`get_recommendations)` on each query in `Final_purchased_products.csv`.\n",
        "2. **Check if the actual purchased product appears in the top 10 recommendations**.\n",
        "3. **Calculate accuracy** (percentage of queries where the purchased product was found).\n",
        "4. **Visualize results**, including:\n",
        "  - A **bar chart** comparing correct vs incorrect predictions.\n",
        "  - A **table** displaying sample queries, top recommendations, and whether the purchase was matched."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf0LBJYXdFWt"
      },
      "source": [
        "Modify the evaluation function to work with **both** `get_recommendations` and `get_recommendations_2`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cdJz4DdqzQk"
      },
      "outputs": [],
      "source": [
        "purchased_df = pd.read_csv('/Users/stephanielonsdale/Final_purchased_products.csv')\n",
        "purchased_df.head()  # Check if the data is loaded correctly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "SXVSW74zv0M3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Convert to lowercase\n",
        "purchased_df[\"final_purchased_product\"] = purchased_df[\"final_purchased_product\"].astype(str).str.lower()\n",
        "\n",
        "# Remove non-alphanumeric characters (keeping spaces)\n",
        "purchased_df[\"final_purchased_product\"] = purchased_df[\"final_purchased_product\"].apply(lambda x: re.sub(r'[^A-Za-z0-9]+', ' ', x).strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDVOjJDcPOlR"
      },
      "source": [
        "The function `evaluate_recommendations` **evaluates the accuracy** of a recommendation system by checking whether the **purchased product** appears in the top-10 recommendations for each query.\n",
        "1. It iterates over each row in `purchased_df`, extracting the **query** and the **final purchased product**.\n",
        "2. It retrieves **top-10 recommendations** using `get_recommendations(query)`.\n",
        "3. It checks if the purchased product is in the **recommended list** and stores the result.\n",
        "4. It converts results into a **DataFrame** and calculates **accuracy** as the percentage of queries where the purchased product was found in the recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "9nJi8z9z1dwC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_recommendations(get_recommendations, purchased_df, top_k=10):\n",
        "    results = []\n",
        "\n",
        "    for index, row in purchased_df.iterrows():\n",
        "        query = row[\"query\"]\n",
        "        purchased_product = row[\"final_purchased_product\"]\n",
        "\n",
        "        # Get recommendations\n",
        "        recommended_products = get_recommendations(query, top_k=top_k)\n",
        "\n",
        "        # Check if purchased product is in the recommendations list\n",
        "        match = True if purchased_product in recommended_products.values else False\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            \"Query\": query,\n",
        "            \"Purchased Product\": purchased_product,\n",
        "            \"Match Found\": match,\n",
        "            \"Top Recommendations\": list(recommended_products.values)\n",
        "        })\n",
        "\n",
        "    # Convert results to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = results_df[\"Match Found\"].sum() / len(results_df) * 100\n",
        "\n",
        "    return accuracy, results_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDzqr1ZVdDoM"
      },
      "source": [
        "Call the function with `get_recommendations`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtyUlWQVc8b8"
      },
      "outputs": [],
      "source": [
        "# Run evaluation\n",
        "accuracy, results_df = evaluate_recommendations(get_recommendations, purchased_df)\n",
        "print(f\"Recommendation Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Display sample results\n",
        "results_df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POiAlGN3QFb9"
      },
      "source": [
        "<font color = 'Blue'>**Accuracy: 76%**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK-zGgn3QZIn"
      },
      "source": [
        "This setup evaluates how well the recommendation system aligns with **real purchases**, providing **both accuracy metrics and ranking insights** for improvement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilMU-g7nVnK7"
      },
      "outputs": [],
      "source": [
        "def find_rank_in_recommendations(row):\n",
        "    try:\n",
        "        return row['Top Recommendations'].index(row['Purchased Product']) + 1  # 1-based index\n",
        "    except ValueError:\n",
        "        return \"Not Found\"  # Explicitly set a string instead of None\n",
        "\n",
        "# Apply the function to find ranks\n",
        "results_df['Purchase Rank'] = results_df.apply(find_rank_in_recommendations, axis=1)\n",
        "\n",
        "# Display the updated dataframe\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pItWTyePDJb8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Convert to categorical for proper ordering in the graph\n",
        "results_df['Purchase Rank'] = pd.Categorical(results_df['Purchase Rank'], ordered=True)\n",
        "\n",
        "# Count occurrences including 'Not Found'\n",
        "rank_counts = results_df['Purchase Rank'].value_counts().sort_index()\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=rank_counts.index, y=rank_counts.values, palette=\"viridis\")\n",
        "\n",
        "plt.xlabel(\"Rank in Recommendations\")\n",
        "plt.ylabel(\"Count of Purchased Products\")\n",
        "plt.title(\"Distribution of Purchased Products in Top Recommendations\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdgIxQmGRV1a"
      },
      "source": [
        "#### **Visualizations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAsA_riWdBhj"
      },
      "source": [
        "**(a) Bar Chart - Match vs. No Match**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3i3FBvFc9nc"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count matches and mismatches\n",
        "match_counts = results_df[\"Match Found\"].value_counts()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=match_counts.index, y=match_counts.values, palette=[\"red\", \"green\"])\n",
        "plt.xticks(ticks=[0, 1], labels=[\"No Match\", \"Match\"])\n",
        "plt.ylabel(\"Number of Queries\")\n",
        "plt.title(\"Recommendation Success Rate\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjabW9cbdAFX"
      },
      "source": [
        "**(b) Table - Not found Queries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwFu10aic-xN"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Show 5 random examples where the recommendation was incorrect\n",
        "display(results_df[results_df[\"Match Found\"] == False].sample(12))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MjIpt6wrfk-"
      },
      "source": [
        "# **Conclusion**\n",
        "\n",
        "- The AI-driven recommendation system successfully enhances <font color='blue'>**product discovery and search relevance** </font>, improving user engagement on ShopEasy.\n",
        "- The modelâ€™s effectiveness in <font color='blue'>**understanding semantic relationships** </font> ensures a data-driven approach to optimizing <font color='blue'>**search rankings and product recommendations** </font>.\n",
        "- Highlights the systemâ€™s <font color='blue'>**ability to capture user intent** </font>, with:\n",
        "  - Precise ranking of products based on <font color='blue'>**semantic similarity rather than simple keyword matching** </font>.\n",
        "  - Reduction in irrelevant search results, improving <font color='blue'>**click-through rates and conversions** </font>.\n",
        "- Demonstrates scalability for <font color='blue'>**large product catalogs** </font>, supporting real-time <font color='blue'>**search and recommendations with precomputed embeddings** </font> efficiently.\n",
        "- Resolves key inefficiencies in <font color='blue'>**traditional keyword-based search methods** </font> while showcasing:\n",
        "  - <font color='blue'>**Innovation** </font> in leveraging <font color='blue'>**NLP-based embeddings for personalized recommendations** </font>.\n",
        "  - Focus on <font color='blue'>**data-driven decision-making** </font> to enhance customer satisfaction and boost sales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection on business impact of AI-powered search systems:\n",
        "\n",
        "AI-powered search systems fundamentally reshape how businesses connect users with information, products, and services. Unlike traditional keyword-based retrieval, which often fails to capture context and intent, semantic search systems interpret meaning, enabling more accurate and personalized recommendations. This shift has several significant business impacts.\n",
        "\n",
        "AI-powered imrpovements can be seen in enhanced customer engagement and experience, higher conversion and retention rates, operational efficiency and scalability, competitive differentiation and innovation, and strategic data utilization.\n",
        "\n",
        "AI-powered search systems are more than a technical upgrade. They are a business enabler. They boost user satisfaction, drive revenue, and create sustainable advantages in competitive industries where personalization and speed are critical. For organizations like ShopEasy, these systems directly translate into stronger engagement, higher sales, and long-term customer trust."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Algorithms-Kernel)",
      "language": "python",
      "name": "algorithms-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
